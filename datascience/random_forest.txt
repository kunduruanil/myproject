sklearn.ensemble.RandomForestClassifier(n_estimators=’warn’, criterion=’gini’, max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0,
 max_features=’auto’, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, 
 verbose=0, warm_start=False, class_weight=None)
 
 parameters :
 n_estimators : integer, optional (default=10):The number of trees in the forest.
Changed in version 0.20: The default value of n_estimators will change from 10 in version 0.20 to 100 in version 0.22.

All other parameters are same as decision tree check in that text file.
 
 definations:
 1.it will form a n decision trees and take the mean of output. form with diffrent samples and observation that genarates random trees this process is called Bootstrap.
 Bootstrap aggregating, also called bagging
 
 Random forest is like bootstrapping algorithm with Decision tree (CART) model. Say, we have 1000 observation in the complete population with 10 variables. 
Random forest tries to build multiple CART models with different samples and different initial variables. For instance,it will take a random sample of 
100 observation and 5 randomly chosen initial variables to build a CART model. It will repeat the process (say) 10 times and then make a final prediction  on each observation.
 Final prediction is a function of each prediction. This final prediction can simply be the mean of each prediction.
